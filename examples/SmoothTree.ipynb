{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth Tree\n",
    "Single decision trees generally overfit, leading to poor predictive performance. Tree ensembles (RF, GBM) perform well, but are black-box models. In this notebook, we investigate whether smoothing the predictions in decision trees can produce a traceable, white-box model with improved predicive accuracy.\n",
    "\n",
    "In a smoothed regression tree, the node values, $s_n$, will be as follows:\n",
    "\n",
    "$$\n",
    "s_n = \\begin{cases}\n",
    "y_n & \\text{n is root}\\\\\n",
    "\\frac{w_n y_n + v_{ss} s_p}{w_n + v_{ss}} & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Where $y_n$ is the mean of the targets of the node n, $s_n$ is the smoothed node value of node n, $s_p$ is the smoothed value of the parent of node n, $v_{ss}$ is the virtual sample size (a free parameter of the model), and $w_n$ is the total weight of data in node n, or the count if the tree is unweighted.\n",
    "\n",
    "Smoothed classification trees are similar, but operate on class probabilities instead of on the mean of the targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes\n",
    "Our first example involves prediction on the *diabetes* dataset. This dataset has 502 examples with 10 predictors. We divide it into a 295 row training set and a 147 row test set. The targets are numeric and are evaluated by mse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((295, 10), (147, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arboretum.datasets import load_diabetes\n",
    "xtr, ytr, xte, yte = load_diabetes()\n",
    "xtr.shape, xte.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare a smoothed regression tree from arboretum to a regression tree and a random forest from scikit-learn. First, we'll just run the models once, then we will investiagte their performance in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from arboretum import SmoothRegressionTree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "dtr = DecisionTreeRegressor(min_samples_leaf=5)\n",
    "rf = RandomForestRegressor(n_estimators=100, min_samples_leaf=5)\n",
    "mytree = SmoothRegressionTree(vss= 5, min_leaf=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5160.6983167743037"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.fit(xtr, ytr)\n",
    "pred = dtr.predict(xte)\n",
    "mse(yte, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4593.5736258148163"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytree.fit(xtr, ytr)\n",
    "pred = mytree.predict(xte)\n",
    "mse(yte, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2942.9805697170409"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(xtr, ytr)\n",
    "pred = rf.predict(xte)\n",
    "mse(yte, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, off-hand, it looks like the smoothed regression tree is in-between one tree and a random forest in terms of accuracy, but closer to one tree. However, it has more free parameters, so we need to investiagte more. We'll give the regular tree one more control parameter so that both models have two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3611.5331249595665, {'max_depth': 8, 'min_samples_leaf': 20})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'min_samples_leaf':[5, 10, 20, 50, 100], 'max_depth':[2,4,8,16, None]}\n",
    "gcv = GridSearchCV(dtr, params, 'neg_mean_squared_error')\n",
    "gcv.fit(xtr, ytr)\n",
    "gcv.best_score_, gcv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is better than the naively set smoothing tree. Note that scikit-learn uses negative mean squared error as a scoring function because `GridSearchCV` maximizes the scoring function. And on the test set, that estimator gets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3898.421419473354"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = gcv.predict(xte)\n",
    "mse(yte, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how does the smoothing tree do? We'll try it two ways, once with `vss` and `min_leaf` set and then with `vss` and `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3855.629545109196, -3599.5965268547347, {'min_leaf': 20, 'vss': 5})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myparams = {'min_leaf':[5, 10, 20, 50, 100], 'vss':[5, 10, 20, 50, 100]}\n",
    "gcv = GridSearchCV(mytree, myparams, 'neg_mean_squared_error')\n",
    "gcv.fit(xtr, ytr)\n",
    "mypred = gcv.predict(xte)\n",
    "mse(yte, mypred), gcv.best_score_, gcv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's about the same. Next we'll try it with the other parameter set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3968.9469274964681, -3924.7853187456703, {'max_depth': 4, 'vss': 50})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myparams = {'max_depth':[2,4,8,16, None], 'vss':[5, 10, 20, 50, 100]}\n",
    "gcv = GridSearchCV(mytree, myparams, 'neg_mean_squared_error')\n",
    "gcv.fit(xtr, ytr)\n",
    "mypred = gcv.predict(xte)\n",
    "mse(yte, mypred), gcv.best_score_, gcv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's worse. So the initial impression that we had, that the smoothing tree was moderately better was due to better model capacity control from the extra parameter. It disappeared when we conducted a search over equal numbers of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS\n",
    "Next up we consider the ALS dataset. This is a wide, noisy dataset with 369 predictors. The training set has 1197 rows and the test set has 625. It is a tough dataset for trees. They often underperform the constant model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1197, 369), (625, 369))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arboretum.datasets import load_als\n",
    "xtr, ytr, xte, yte = load_als()\n",
    "xtr.shape, xte.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constant model gets mse of about 0.32, which is better than both the tree and smoothed tree (at these parameters), but worse than the RF model. The 0.26 of the RF model is a good score on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32037244903736767"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(yte, 0 * yte + ytr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45225023825751176"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.fit(xtr, ytr)\n",
    "pred = dtr.predict(xte)\n",
    "mse(yte, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36398480589778592"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytree.fit(xtr, ytr)\n",
    "pred = mytree.predict(xte)\n",
    "mse(yte, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25852639120867782"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.n_estimators = 100\n",
    "rf.fit(xtr, ytr)\n",
    "pred = rf.predict(xte)\n",
    "mse(yte, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $v_{ss}$ parameter can be changed without refitting on an `arboretum.SmoothRegressionTree`. For this noisy data, much higher smoothing values are better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2944062345391758"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytree.vss = 100\n",
    "pred = mytree.predict(xte)\n",
    "mse(yte, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, it looks like smoothing trees are in between the results for a single tree and an RF. Like before, we'll compare the smoothing tree with `vss` and one other control parameter to a regular tree with two control parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.27856303321060677,\n",
       " -0.28591222452298265,\n",
       " {'max_depth': None, 'min_samples_leaf': 200})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'min_samples_leaf':[5, 10, 20, 50, 100, 200, 400], 'max_depth':[2,4,8,16, None]}\n",
    "gcv = GridSearchCV(dtr, params, 'neg_mean_squared_error')\n",
    "gcv.fit(xtr, ytr)\n",
    "pred = gcv.predict(xte)\n",
    "mse(yte, pred), gcv.best_score_, gcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.27818923925487532, -0.28039185551835893, {'min_leaf': 50, 'vss': 200})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myparams = {'min_leaf':[5, 10, 20, 50, 100], 'vss':[5, 10, 20, 50, 100, 200, 400]}\n",
    "gcv = GridSearchCV(mytree, myparams, 'neg_mean_squared_error')\n",
    "gcv.fit(xtr, ytr)\n",
    "mypred = gcv.predict(xte)\n",
    "mse(yte, mypred), gcv.best_score_, gcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.28229031274129485, -0.28162959756580547, {'max_depth': 8, 'vss': 400})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myparams = {'max_depth':[2,4,8,16, None], 'vss':[5, 10, 20, 50, 100, 200, 400]}\n",
    "gcv = GridSearchCV(mytree, myparams, 'neg_mean_squared_error')\n",
    "gcv.fit(xtr, ytr)\n",
    "mypred = gcv.predict(xte)\n",
    "mse(yte, mypred), gcv.best_score_, gcv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So once again, on closer examination, the smoothing tree is not better than a well-tuned regular tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "On classification tasks, the initial positive results found above on regression problems did not occur, at least for accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "We might wonder if there is any benefit to using smoothing trees in a random forest ensemble. We can monkey-patch an `arboretum.RFRegressor` to find out. We run the forest once on small data to get numba to jit the RF code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFRegressor(n_trees=30, min_leaf=5, max_features=None, max_depth=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arboretum import RFRegressor\n",
    "myrf = RFRegressor()\n",
    "myrf.base_estimator = mytree\n",
    "myrf.fit(xtr[:10], ytr[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25731757233969138"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrf.n_trees = 100\n",
    "myrf.fit(xtr, ytr)\n",
    "pred = myrf.predict(xte)\n",
    "mse(yte, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From before we got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25739208636018618"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(xtr, ytr)\n",
    "pred = rf.predict(xte)\n",
    "mse(yte, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like the smoothing doesn't help any in an RF model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Smoothing trees initially looked promising, however, closer investigation indicates that the initial positive results were due to having better control of overfitting due to having an extra control parameter. In comparing two-parameter models after a grid search, smoothing trees were not better than regular trees. In summary, well-tuned decision trees perform as well as smoothing trees, given the same number of control paramters."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tree_dev]",
   "language": "python",
   "name": "conda-env-tree_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
